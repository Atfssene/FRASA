{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Summarization Model - FRASA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1rOeaQy-nSG8pOejCG-i9iGk8pTsdRpSM",
      "authorship_tag": "ABX9TyMyMVcFrjEvUq5aOrFsiM1Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Atfssene/FRASA/blob/main/Text_Summarization_Model_FRASA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABUbyYSyrmBZ"
      },
      "source": [
        "# Text Summarization Model\n",
        "\n",
        "In this notebook, we will create a model for text summarization task. TextRank and SumBasic will be our feature extraction from senteces to create a weights that will be feeded to a neural networks. Let's start!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_nXmMwCsg0U"
      },
      "source": [
        "## Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iljjWCIHLDaL",
        "outputId": "bf1649b5-36dc-44ea-ca86-8d182384f43b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "# !pip install fasttext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQyuInu0Xx22"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import numpy as np\n",
        "# import gzip\n",
        "import networkx as nx\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# import fasttext\n",
        "# import fasttext.util"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbNj-Rs1vBC8"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp_uze8hvDZp",
        "outputId": "ad44886a-7d24-4b1c-f60f-9d3522295337"
      },
      "source": [
        "train = tf.keras.utils.get_file('train.csv', 'https://raw.githubusercontent.com/Atfssene/FRASA/main/Text%20Summarization/train.csv')\n",
        "test = tf.keras.utils.get_file('test.csv', 'https://raw.githubusercontent.com/Atfssene/FRASA/main/Text%20Summarization/test.csv')\n",
        "\n",
        "df_train = pd.read_csv(train)\n",
        "df_test = pd.read_csv(test)\n",
        "df_train.info()\n",
        "df_test.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/Atfssene/FRASA/main/Text%20Summarization/train.csv\n",
            "63160320/63156551 [==============================] - 1s 0us/step\n",
            "Downloading data from https://raw.githubusercontent.com/Atfssene/FRASA/main/Text%20Summarization/test.csv\n",
            "9879552/9872406 [==============================] - 0s 0us/step\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15012 entries, 0 to 15011\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   labels      15012 non-null  object\n",
            " 1   paragraphs  15012 non-null  object\n",
            " 2   summary     15012 non-null  object\n",
            " 3   clean_text  15012 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 469.2+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3762 entries, 0 to 3761\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   labels      3762 non-null   object\n",
            " 1   paragraphs  3762 non-null   object\n",
            " 2   summary     3762 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 88.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQcw4FfCv8UV"
      },
      "source": [
        "## Create TextRank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0U4uGqfP2AX"
      },
      "source": [
        "Download Indonesian word vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-Ac3r7cZNy5"
      },
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.vec.gz\n",
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.bin.gz"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1c-5WcZfDx-"
      },
      "source": [
        "Unzipping..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClrUoK8keMbJ"
      },
      "source": [
        "# !gunzip cc.id.300.vec.gz\n",
        "# !gunzip cc.id.300.bin.gz\n",
        "# from gensim.models.keyedvectors import KeyedVectors\n",
        "# kv = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/model_summarization/cc.id.300.vec', limit=400000)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDluorS_9PBa"
      },
      "source": [
        "# kv.save_word2vec_format(\"/content/cc.id.vec\", binary=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSXuO9VPfziR"
      },
      "source": [
        "Load pretrained words embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmXywkenPb5_",
        "outputId": "fe0bdecc-1af9-4eca-98fc-dd160391040f"
      },
      "source": [
        "word_embeddings = {}\n",
        "f = open('/content/drive/MyDrive/model_summarization/cc.id.vec', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    word_embeddings[word] = coefs\n",
        "f.close()\n",
        "\n",
        "len(word_embeddings)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtlJXhxeBCKO"
      },
      "source": [
        "sentences = []\n",
        "for s in df_train['paragraphs'].head(1):\n",
        "  sentences.append(sent_tokenize(s))\n",
        "sentences = [y for x in sentences for y in x]\n",
        "\n",
        "clean_sentences = []\n",
        "for s in df_train['clean_text'].head(1):\n",
        "  clean_sentences.append(sent_tokenize(s))\n",
        "clean_sentences = [y for x in clean_sentences for y in x]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaPB2xyhkGxX"
      },
      "source": [
        "sentence_vectors = []\n",
        "for i in clean_sentences:\n",
        "  if len(i) != 0:\n",
        "    v = sum([word_embeddings.get(w, np.zeros((300,))) for w in i.split()])/(len(i.split())+0.001)\n",
        "  else:\n",
        "    v = np.zeros((300,))\n",
        "  sentence_vectors.append(v)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWiTFLs8YWgS"
      },
      "source": [
        "sim_mat = np.zeros([len(sentences), len(sentences)])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ptsdi65Bhmp"
      },
      "source": [
        "for i in range(len(sentences)):\n",
        "  for j in range(len(sentences)):\n",
        "    if i != j:\n",
        "      sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,300), sentence_vectors[j].reshape(1,300))[0,0]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7vMstrfYZRZ"
      },
      "source": [
        "nx_graph = nx.from_numpy_array(sim_mat)\n",
        "scores = nx.pagerank(nx_graph)\n",
        "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5Xmp-oHeOkg",
        "outputId": "0739f3d9-27fb-41cc-91d1-59d1c4c8e420"
      },
      "source": [
        "# [(i, s) for i,s in enumerate(sentences)]\n",
        "for text in sentences:\n",
        "  print(text)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jakarta, CNN Indonesia - - Dokter Ryan Thamrin, yang terkenal lewat acara Dokter Oz Indonesia, meninggal dunia pada Jumat (4 / 8) dini hari.\n",
            "Dokter Lula Kamal yang merupakan selebriti sekaligus rekan kerja Ryan menyebut kawannya itu sudah sakit sejak setahun yang lalu.\n",
            "Lula menuturkan, sakit itu membuat Ryan mesti vakum dari semua kegiatannya, termasuk menjadi pembawa acara Dokter Oz Indonesia.\n",
            "Kondisi itu membuat Ryan harus kembali ke kampung halamannya di Pekanbaru, Riau untuk menjalani istirahat. \"\n",
            "Setahu saya dia orangnya sehat, tapi tahun lalu saya dengar dia sakit.\n",
            "( Karena) sakitnya, ia langsung pulang ke Pekanbaru, jadi kami yang mau jenguk juga susah.\n",
            "Barangkali mau istirahat, ya betul juga, kalau di Jakarta susah isirahatnya, \" kata Lula kepada CNNIndonesia.com, Jumat (4 / 8).\n",
            "Lula yang mengenal Ryan sejak sebelum aktif berkarier di televisi mengaku belum sempat membesuk Ryan lantaran lokasi yang jauh.\n",
            "Dia juga tak tahu penyakit apa yang diderita Ryan. \"\n",
            "Itu saya enggak tahu, belum sempat jenguk dan enggak selamanya bisa dijenguk juga.\n",
            "Enggak tahu berat sekali apa bagaimana, \" tutur Ryan.\n",
            "Walau sudah setahun menderita sakit, Lula tak mengetahui apa penyebab pasti kematian Dr Oz Indonesia itu.\n",
            "Meski demikian, ia mendengar beberapa kabar yang menyebut bahwa penyebab Ryan meninggal adalah karena jatuh di kamar mandi.\n",
            "“ Saya tidak tahu, barangkali penyakit yang dulu sama yang sekarang berbeda, atau penyebab kematiannya beda dari penyakit sebelumnya.\n",
            "Kita kan enggak bisa mengambil kesimpulan, \" kata Lula.\n",
            "Ryan Thamrin terkenal sebagai dokter yang rutin membagikan tips dan informasi kesehatan lewat tayangan Dokter Oz Indonesia.\n",
            "Ryan menempuh Pendidikan Dokter pada tahun 2002 di Fakultas Kedokteran Universitas Gadjah Mada.\n",
            "Dia kemudian melanjutkan pendidikan Klinis Kesehatan Reproduksi dan Penyakit Menular Seksual di Mahachulalongkornrajavidyalaya University, Bangkok, Thailand pada 2004.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXvu2F01ZGqp",
        "outputId": "fe431f61-4169-4bb1-c92d-48b63d46b3fe"
      },
      "source": [
        "# for i in range(3):\n",
        "#   print(ranked_sentences[i][1])\n",
        "for i in ranked_sentences:\n",
        "  print(i)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.06091013588314788, 'Lula menuturkan, sakit itu membuat Ryan mesti vakum dari semua kegiatannya, termasuk menjadi pembawa acara Dokter Oz Indonesia.')\n",
            "(0.05986087469041391, 'Dokter Lula Kamal yang merupakan selebriti sekaligus rekan kerja Ryan menyebut kawannya itu sudah sakit sejak setahun yang lalu.')\n",
            "(0.05837850794448731, 'Setahu saya dia orangnya sehat, tapi tahun lalu saya dengar dia sakit.')\n",
            "(0.05811819645865672, '“ Saya tidak tahu, barangkali penyakit yang dulu sama yang sekarang berbeda, atau penyebab kematiannya beda dari penyakit sebelumnya.')\n",
            "(0.05776311916576284, 'Meski demikian, ia mendengar beberapa kabar yang menyebut bahwa penyebab Ryan meninggal adalah karena jatuh di kamar mandi.')\n",
            "(0.05773574513429258, 'Lula yang mengenal Ryan sejak sebelum aktif berkarier di televisi mengaku belum sempat membesuk Ryan lantaran lokasi yang jauh.')\n",
            "(0.05656949054199408, 'Jakarta, CNN Indonesia - - Dokter Ryan Thamrin, yang terkenal lewat acara Dokter Oz Indonesia, meninggal dunia pada Jumat (4 / 8) dini hari.')\n",
            "(0.05628137259134671, 'Ryan Thamrin terkenal sebagai dokter yang rutin membagikan tips dan informasi kesehatan lewat tayangan Dokter Oz Indonesia.')\n",
            "(0.05626494382459023, '( Karena) sakitnya, ia langsung pulang ke Pekanbaru, jadi kami yang mau jenguk juga susah.')\n",
            "(0.056198999719088594, 'Barangkali mau istirahat, ya betul juga, kalau di Jakarta susah isirahatnya, \" kata Lula kepada CNNIndonesia.com, Jumat (4 / 8).')\n",
            "(0.0559482929036589, 'Enggak tahu berat sekali apa bagaimana, \" tutur Ryan.')\n",
            "(0.05588348948999913, 'Walau sudah setahun menderita sakit, Lula tak mengetahui apa penyebab pasti kematian Dr Oz Indonesia itu.')\n",
            "(0.05466616578431332, 'Itu saya enggak tahu, belum sempat jenguk dan enggak selamanya bisa dijenguk juga.')\n",
            "(0.05358955066414319, 'Dia juga tak tahu penyakit apa yang diderita Ryan. \"')\n",
            "(0.05168620622168481, 'Ryan menempuh Pendidikan Dokter pada tahun 2002 di Fakultas Kedokteran Universitas Gadjah Mada.')\n",
            "(0.050898801974925634, 'Kondisi itu membuat Ryan harus kembali ke kampung halamannya di Pekanbaru, Riau untuk menjalani istirahat. \"')\n",
            "(0.05009205343710138, 'Dia kemudian melanjutkan pendidikan Klinis Kesehatan Reproduksi dan Penyakit Menular Seksual di Mahachulalongkornrajavidyalaya University, Bangkok, Thailand pada 2004.')\n",
            "(0.04915405357039277, 'Kita kan enggak bisa mengambil kesimpulan, \" kata Lula.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX2iAyYHN6lt"
      },
      "source": [
        "## Create SumBasic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH8wH5vrxycB",
        "outputId": "a2296022-c0f8-431a-87db-9220d5e6bfb9"
      },
      "source": [
        "for sentence in (sent_tokenize(processed)):\n",
        "  for word in word_tokenize(sentence):\n",
        "    print(word)\n",
        "    break"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jakarta\n",
            "dokter\n",
            "lula\n",
            "kondisi\n",
            "setahu\n",
            "sakitnya\n",
            "barangkali\n",
            "lula\n",
            "tahu\n",
            "enggak\n",
            "enggak\n",
            "setahun\n",
            "meski\n",
            "tahu\n",
            "enggak\n",
            "ryan\n",
            "ryan\n",
            "kemudian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0s6l_uXZlB_",
        "outputId": "0c99d0ca-537c-41c1-cde6-0017e3ade89f"
      },
      "source": [
        "frequency = {}\n",
        "processed =  df_train['clean_text'].iloc[0]\n",
        "for word in word_tokenize(processed):\n",
        "  if word.isalnum():\n",
        "    if word not in frequency.keys():\n",
        "      frequency[word]=1\n",
        "    else:\n",
        "      frequency[word]+=1\n",
        "max_fre = max(frequency.values())\n",
        "for word in frequency.keys():\n",
        "    frequency[word]=(frequency[word]/max_fre)\n",
        "    \n",
        "scores = {}\n",
        "for i, sentence in enumerate((sent_tokenize(processed))):\n",
        "  \n",
        "  for word in word_tokenize(sentence):\n",
        "    \n",
        "    if word in frequency.keys():\n",
        "        if i not in scores.keys():\n",
        "          scores[i] = frequency[word]\n",
        "        else:\n",
        "          scores[i] += frequency[word]\n",
        "scores"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 4.727272727272726,\n",
              " 1: 3.909090909090908,\n",
              " 2: 4.09090909090909,\n",
              " 3: 1.9999999999999998,\n",
              " 4: 1.0909090909090908,\n",
              " 5: 0.9090909090909092,\n",
              " 6: 2.0,\n",
              " 7: 3.7272727272727266,\n",
              " 8: 1.8181818181818183,\n",
              " 9: 1.6363636363636362,\n",
              " 10: 2.090909090909091,\n",
              " 11: 2.0909090909090904,\n",
              " 12: 2.2727272727272725,\n",
              " 13: 2.181818181818181,\n",
              " 14: 1.2727272727272727,\n",
              " 15: 3.9090909090909083,\n",
              " 16: 2.545454545454545,\n",
              " 17: 1.636363636363636}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu9-ScD3r2NK"
      },
      "source": [
        "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFOMPvZo3Znw",
        "outputId": "c346a6e6-c283-4147-9c75-2c6cbfb7bbec"
      },
      "source": [
        "for i in ranked_sentences:\n",
        "  print(i)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4.727272727272726, 'Jakarta, CNN Indonesia - - Dokter Ryan Thamrin, yang terkenal lewat acara Dokter Oz Indonesia, meninggal dunia pada Jumat (4 / 8) dini hari.')\n",
            "(4.09090909090909, 'Lula menuturkan, sakit itu membuat Ryan mesti vakum dari semua kegiatannya, termasuk menjadi pembawa acara Dokter Oz Indonesia.')\n",
            "(3.9090909090909083, 'Ryan Thamrin terkenal sebagai dokter yang rutin membagikan tips dan informasi kesehatan lewat tayangan Dokter Oz Indonesia.')\n",
            "(3.909090909090908, 'Dokter Lula Kamal yang merupakan selebriti sekaligus rekan kerja Ryan menyebut kawannya itu sudah sakit sejak setahun yang lalu.')\n",
            "(3.7272727272727266, 'Lula yang mengenal Ryan sejak sebelum aktif berkarier di televisi mengaku belum sempat membesuk Ryan lantaran lokasi yang jauh.')\n",
            "(2.545454545454545, 'Ryan menempuh Pendidikan Dokter pada tahun 2002 di Fakultas Kedokteran Universitas Gadjah Mada.')\n",
            "(2.2727272727272725, 'Meski demikian, ia mendengar beberapa kabar yang menyebut bahwa penyebab Ryan meninggal adalah karena jatuh di kamar mandi.')\n",
            "(2.181818181818181, '“ Saya tidak tahu, barangkali penyakit yang dulu sama yang sekarang berbeda, atau penyebab kematiannya beda dari penyakit sebelumnya.')\n",
            "(2.090909090909091, 'Enggak tahu berat sekali apa bagaimana, \" tutur Ryan.')\n",
            "(2.0909090909090904, 'Walau sudah setahun menderita sakit, Lula tak mengetahui apa penyebab pasti kematian Dr Oz Indonesia itu.')\n",
            "(2.0, 'Barangkali mau istirahat, ya betul juga, kalau di Jakarta susah isirahatnya, \" kata Lula kepada CNNIndonesia.com, Jumat (4 / 8).')\n",
            "(1.9999999999999998, 'Kondisi itu membuat Ryan harus kembali ke kampung halamannya di Pekanbaru, Riau untuk menjalani istirahat. \"')\n",
            "(1.8181818181818183, 'Dia juga tak tahu penyakit apa yang diderita Ryan. \"')\n",
            "(1.6363636363636362, 'Itu saya enggak tahu, belum sempat jenguk dan enggak selamanya bisa dijenguk juga.')\n",
            "(1.636363636363636, 'Dia kemudian melanjutkan pendidikan Klinis Kesehatan Reproduksi dan Penyakit Menular Seksual di Mahachulalongkornrajavidyalaya University, Bangkok, Thailand pada 2004.')\n",
            "(1.2727272727272727, 'Kita kan enggak bisa mengambil kesimpulan, \" kata Lula.')\n",
            "(1.0909090909090908, 'Setahu saya dia orangnya sehat, tapi tahun lalu saya dengar dia sakit.')\n",
            "(0.9090909090909092, '( Karena) sakitnya, ia langsung pulang ke Pekanbaru, jadi kami yang mau jenguk juga susah.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rniaorg6CA3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbNDqOK86Kjg"
      },
      "source": [
        "## Neural Network"
      ]
    }
  ]
}